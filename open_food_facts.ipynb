{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_rows\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.read_csv(\n",
    "    \"files/fr.openfoodfacts.org.products.csv\", sep=\"\\t\", low_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "foods.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "foods.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(foods.isnull().mean().round(2)).sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "msno.bar(foods)\n",
    "plt.axvline(0.5, color=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Clean and filter features and product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\n",
    "    \"url\",\n",
    "    \"code\",\n",
    "    \"creator\",\n",
    "    \"created_datetime\",\n",
    "    \"last_modified_datetime\",\n",
    "    \"product_name\",\n",
    "    \"generic_name\",\n",
    "    \"packaging\",\n",
    "    \"packaging_tags\",\n",
    "    \"brands_tags\",\n",
    "    \"brands\",\n",
    "    \"categories\",\n",
    "    \"categories_tags\",\n",
    "    \"categories_fr\",\n",
    "    \"origins\",\n",
    "    \"origins_tags\",\n",
    "    \"manufacturing_places\",\n",
    "    \"manufacturing_places_tags\",\n",
    "    \"labels\",\n",
    "    \"labels_tags\",\n",
    "    \"labels_fr\",\n",
    "    \"emb_codes\",\n",
    "    \"emb_codes_tags\",\n",
    "    \"first_packaging_code_geo\",\n",
    "    \"cities\",\n",
    "    \"cities_tags\",\n",
    "    \"purchase_places\",\n",
    "    \"stores\",\n",
    "    \"countries\",\n",
    "    \"countries_tags\",\n",
    "    \"countries_fr\",\n",
    "    \"ingredients_text\",\n",
    "    \"traces\",\n",
    "    \"traces_tags\",\n",
    "    \"no_nutriments\",\n",
    "    \"additives\",\n",
    "    \"additives_tags\",\n",
    "    \"ingredients_from_palm_oil\",\n",
    "    \"ingredients_from_palm_oil_tags\",\n",
    "    \"ingredients_that_may_be_from_palm_oil\",\n",
    "    \"ingredients_that_may_be_from_palm_oil_tags\",\n",
    "    \"nutrition_grade_fr\",\n",
    "    \"nutrition_grade_uk\",\n",
    "    \"main_category\",\n",
    "    \"main_category_fr\",\n",
    "    \"image_url\",\n",
    "    \"image_small_url\",\n",
    "    \"allergens\",\n",
    "    \"allergens_fr\",\n",
    "    \"traces_fr\",\n",
    "    \"additives_fr\",\n",
    "    \"pnns_groups_1\",\n",
    "    \"pnns_groups_2\",\n",
    "    \"states\",\n",
    "    \"states_tags\",\n",
    "    \"states_fr\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_filter_features_and_product(\n",
    "    df: pd.DataFrame, feature: str, sub_features=List[str]\n",
    "):\n",
    "    df[feature] = df[feature].replace(\n",
    "        {\n",
    "            \"cereals\": \"Cereals\",\n",
    "            \"fruits\": \"Fruits\",\n",
    "            \"legumes\": \"Legumes\",\n",
    "            \"pastries\": \"Pastries\",\n",
    "            \"nuts\": \"Nuts\",\n",
    "            \"vegetables\": \"Vegetables\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    categorical_foods = foods[CATEGORICAL_FEATURES]\n",
    "\n",
    "    categorical_foods_mean_null_by_column = categorical_foods.isnull().mean()\n",
    "    missing_percentage = categorical_foods_mean_null_by_column[feature] * 100\n",
    "\n",
    "    if missing_percentage < 50:\n",
    "        return display(\n",
    "            HTML(\n",
    "                f\"\"\"\n",
    "                    <p style='color:orange;'>The feature {feature} has less than 50% of missing values ({round(missing_percentage, 1)} %).</p>\n",
    "                    \"<p style='color:red;'>Consider choosing another feature.</p>\"\n",
    "                     <hr style=\"border:1px solid #000;\" />\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"\"\"\n",
    "                <p style='color:green;'>The feature {feature} has more than 50% of missing values ({round(missing_percentage, 1)} %).</p>\n",
    "                <hr style=\"border:1px solid #000;\" />\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "    df1 = df.copy()\n",
    "    %matplotlib inline\n",
    "    msno.matrix(df1)\n",
    "    plt.axvline(0.5, color=\"r\")\n",
    "\n",
    "    df = df.dropna(subset=[feature])\n",
    "    df = df[df[feature] != \"unknown\"]\n",
    "\n",
    "    sub_features_foods = df[sub_features]\n",
    "\n",
    "    sub_features_foods_mean_null_by_column = sub_features_foods.isnull().mean()\n",
    "\n",
    "    at_least_sub_feature_with_missing_values_gt_50_percent = False\n",
    "    for sub_feature in sub_features:\n",
    "        missing_percentage = sub_features_foods_mean_null_by_column[sub_feature] * 100\n",
    "\n",
    "        if missing_percentage > 50:\n",
    "            at_least_sub_feature_with_missing_values_gt_50_percent = True\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"<p style='color:orange;'>The feature {sub_feature} has more than 50% of missing values ({round(missing_percentage, 1)} %).</p>\"\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"<p style='color:green;'>The feature {sub_feature} has less than 50% of missing values ({round(missing_percentage, 1)} %).</p>\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if at_least_sub_feature_with_missing_values_gt_50_percent:\n",
    "        display(\n",
    "            HTML(\n",
    "                \"<p style='color:red;'>At least one feature has more than 50% of missing values. Consider choosing another feature.</p>\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    sub_features_foods = sub_features_foods.copy()\n",
    "\n",
    "    sub_features_foods = sub_features_foods.dropna(\n",
    "        subset=[\n",
    "            \"product_name\",\n",
    "            \"brands\",\n",
    "            \"packaging\",\n",
    "            \"quantity\",\n",
    "            \"countries\",\n",
    "            \"ingredients_text\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sub_features_foods = sub_features_foods.dropna(\n",
    "        subset=[\n",
    "            \"proteins_100g\",\n",
    "            \"carbohydrates_100g\",\n",
    "            \"sugars_100g\",\n",
    "            \"fat_100g\",\n",
    "            \"saturated-fat_100g\",\n",
    "        ],\n",
    "        how=\"all\",\n",
    "    )\n",
    "\n",
    "    sub_features_foods = sub_features_foods.drop_duplicates(\n",
    "        subset=[\n",
    "            \"product_name\",\n",
    "            \"brands\",\n",
    "            \"packaging\",\n",
    "            \"quantity\",\n",
    "            \"countries\",\n",
    "            \"ingredients_text\",\n",
    "            \"proteins_100g\",\n",
    "            \"carbohydrates_100g\",\n",
    "            \"sugars_100g\",\n",
    "            \"fat_100g\",\n",
    "            \"saturated-fat_100g\",\n",
    "        ],\n",
    "        keep=False,\n",
    "    )\n",
    "    display(msno.bar(sub_features_foods))\n",
    "    return sub_features_foods, df1\n",
    "\n",
    "\n",
    "cleaned_df, df1 = clean_and_filter_features_and_product(\n",
    "    foods,\n",
    "    \"pnns_groups_2\",\n",
    "    [\n",
    "        \"product_name\",\n",
    "        \"pnns_groups_2\",\n",
    "        \"nutrition_grade_fr\",\n",
    "        \"brands\",\n",
    "        \"packaging\",\n",
    "        \"quantity\",\n",
    "        \"countries\",\n",
    "        \"ingredients_text\",\n",
    "        \"code\",\n",
    "        \"proteins_100g\",\n",
    "        \"carbohydrates_100g\",\n",
    "        \"sugars_100g\",\n",
    "        \"fat_100g\",\n",
    "        \"saturated-fat_100g\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Je ne garde pas les colonnes salt_100g et energy_100g.\n",
    "\n",
    "La colonne salt_100g contient des valeurs qui correspondent de temps en temps au pourcentage de sodium ou de sel en mg. Je n'ai pas trouvé de relation qui puisse m'aider à automiser la conversion.\n",
    "\n",
    "La colonne energy_100g contient des valeurs soit en kJ soit en kcal. Je n'ai aussi pas trouvé de moyen pour automatiser la conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Manage outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check_outliers = [\n",
    "    \"proteins_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "]\n",
    "\n",
    "cleaned_df[columns_to_check_outliers] = cleaned_df[columns_to_check_outliers].where(\n",
    "    (cleaned_df[columns_to_check_outliers] >= 0)\n",
    "    & (cleaned_df[columns_to_check_outliers] <= 100),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "\n",
    "food_groups = cleaned_df.pnns_groups_2.unique()\n",
    "\n",
    "for column in columns_to_check_outliers:\n",
    "    outlier_column = f\"{column}_is_outlier\"\n",
    "    cleaned_df[outlier_column] = False\n",
    "\n",
    "    grouped = cleaned_df.groupby(\"pnns_groups_2\")\n",
    "\n",
    "    for name, group in grouped:\n",
    "        q1 = group[column].quantile(0.25)\n",
    "        q3 = group[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        lower_bounce = q1 - 1.5 * iqr\n",
    "        upper_bounce = q3 + 1.5 * iqr\n",
    "\n",
    "        outliers = (group[column] < lower_bounce) | (group[column] > upper_bounce)\n",
    "\n",
    "        cleaned_df.loc[group.index, outlier_column] = outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Manage empty values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in food_groups:\n",
    "    for column in columns_to_check_outliers:\n",
    "        skewness = cleaned_df[cleaned_df[\"pnns_groups_2\"] == group][column].skew()\n",
    "        if np.isnan(skewness):\n",
    "            continue\n",
    "        elif abs(skewness) >= 1:\n",
    "            strategy = \"median\"\n",
    "        elif abs(skewness) < 0.5:\n",
    "            strategy = \"mean\"\n",
    "        else:\n",
    "            strategy = \"median\"\n",
    "\n",
    "        imputer = SimpleImputer(strategy=strategy)\n",
    "        group_data = cleaned_df[cleaned_df[\"pnns_groups_2\"] == group]\n",
    "        imputed_values = imputer.fit_transform(group_data[[column]])\n",
    "        cleaned_df.loc[cleaned_df[\"pnns_groups_2\"] == group, column] = imputed_values\n",
    "\n",
    "        imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        group_data = cleaned_df[cleaned_df[\"pnns_groups_2\"] == group]\n",
    "        imputed_values = imputer.fit_transform(group_data[[\"nutrition_grade_fr\"]])\n",
    "        cleaned_df.loc[cleaned_df[\"pnns_groups_2\"] == group, \"nutrition_grade_fr\"] = (\n",
    "            imputed_values\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Univariate and bivariate analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Univariate analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_groups_count = cleaned_df[\"pnns_groups_2\"].value_counts().head(5)\n",
    "display(top_5_groups_count)\n",
    "analysis_df = cleaned_df.copy()\n",
    "\n",
    "columns_to_analyse = (\n",
    "    \"proteins_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    ")\n",
    "\n",
    "\n",
    "def plot_histogram(df):\n",
    "    for column in columns_to_analyse:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.hist(\n",
    "            df[column],\n",
    "        )\n",
    "        plt.title(f\"Histogram of {column}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_box(df):\n",
    "    for column in columns_to_analyse:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.boxplot(df[column], vert=False)\n",
    "        plt.title(f\"Boxplot of {column}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie_chart(df):\n",
    "    # Calculate the counts of each category\n",
    "    category_counts = df[\"nutrition_grade_fr\"].value_counts()\n",
    "\n",
    "    # Plot the pie chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(\n",
    "        category_counts,\n",
    "        labels=category_counts.index,\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "        colors=plt.cm.Paired.colors,\n",
    "    )\n",
    "    plt.title(\"Pie Chart of nutrition grade\")\n",
    "    plt.axis(\"equal\")  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage: Plot pie chart for a categorical column\n",
    "plot_pie_chart(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Bi variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_df = cleaned_df[cleaned_df[\"pnns_groups_2\"] == \"One-dish meals\"][[ \"proteins_100g\", \"carbohydrates_100g\", \"sugars_100g\", \"fat_100g\"]]\n",
    "# tmp_df = cleaned_df[[ \"proteins_100g\", \"carbohydrates_100g\", \"sugars_100g\", \"fat_100g\"]]\n",
    "\n",
    "nutrition_grade_encoder = OrdinalEncoder(categories=[[\"a\", \"b\", \"c\", \"d\", \"e\"]])\n",
    "\n",
    "cleaned_df[\"nutrition_grade_fr_numeric\"] = nutrition_grade_encoder.fit_transform(\n",
    "    cleaned_df[[\"nutrition_grade_fr\"]]\n",
    ")\n",
    "corr_matrix = cleaned_df[\n",
    "    [\n",
    "        \"proteins_100g\",\n",
    "        \"carbohydrates_100g\",\n",
    "        \"sugars_100g\",\n",
    "        \"fat_100g\",\n",
    "        \"saturated-fat_100g\",\n",
    "        \"nutrition_grade_fr_numeric\",\n",
    "    ]\n",
    "].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.title(\"Heatmap of Nutritional Values by Product\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_food_group(df):\n",
    "    for column in columns_to_analyse:\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.ylabel(\"Food groups\")\n",
    "        plt.xlabel(column.split(\"_\")[0])\n",
    "\n",
    "        sns.violinplot(y=\"pnns_groups_2\", x=column, data=cleaned_df)\n",
    "\n",
    "\n",
    "scatter_food_group(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Multi variate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = cleaned_df[\n",
    "    [\n",
    "        \"proteins_100g\",\n",
    "        \"carbohydrates_100g\",\n",
    "        \"sugars_100g\",\n",
    "        \"fat_100g\",\n",
    "        \"saturated-fat_100g\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(scaled_df)\n",
    "\n",
    "idx = [\"mean\", \"std\"]\n",
    "display(pd.DataFrame(data_scaled).describe().round(2).loc[idx, :])\n",
    "\n",
    "n_components = 5\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_components = pca.fit(data_scaled)\n",
    "\n",
    "# Créer un DataFrame avec les deux composantes principales\n",
    "# pca_df = pd.DataFrame(data=pca_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "display(pca_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scree = (pca.explained_variance_ratio_ * 100).round(2)\n",
    "scree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scree_cum = scree.cumsum().round()\n",
    "scree_cum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = range(1, n_components + 1)\n",
    "list(x_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x_list, scree)\n",
    "plt.plot(x_list, scree_cum, c=\"red\", marker=\"o\")\n",
    "plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "plt.ylabel(\"pourcentage d'inertie\")\n",
    "plt.title(\"Eboulis des valeurs propres\")\n",
    "plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pca.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pd.DataFrame(pcs)\n",
    "pcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "sns.heatmap(pcs.T, vmin=-1, vmax=1, annot=True, cmap=\"coolwarm\", fmt=\"0.2f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 0, 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for i in range(0, pca.components_.shape[1]):\n",
    "    ax.arrow(\n",
    "        0,\n",
    "        0,  # Start the arrow at the origin\n",
    "        pca.components_[0, i],  # 0 for PC1\n",
    "        pca.components_[1, i],  # 1 for PC2\n",
    "        head_width=0.07,\n",
    "        head_length=0.07,\n",
    "        width=0.02,\n",
    "    )\n",
    "\n",
    "    plt.text(pca.components_[0, i] + 0.05, pca.components_[1, i] + 0.05, features[i])\n",
    "\n",
    "# affichage des lignes horizontales et verticales\n",
    "plt.plot([-1, 1], [0, 0], color=\"grey\", ls=\"--\")\n",
    "plt.plot([0, 0], [-1, 1], color=\"grey\", ls=\"--\")\n",
    "\n",
    "\n",
    "# nom des axes, avec le pourcentage d'inertie expliqué\n",
    "plt.xlabel(\"F{} ({}%)\".format(x + 1, round(100 * pca.explained_variance_ratio_[x], 1)))\n",
    "plt.ylabel(\"F{} ({}%)\".format(y + 1, round(100 * pca.explained_variance_ratio_[y], 1)))\n",
    "\n",
    "plt.title(\"Cercle des corrélations (F{} et F{})\".format(x + 1, y + 1))\n",
    "\n",
    "\n",
    "an = np.linspace(0, 2 * np.pi, 100)\n",
    "plt.plot(np.cos(an), np.sin(an))  # Add a unit circle for scale\n",
    "plt.axis(\"equal\")\n",
    "plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing numpy for linspace and trigonometric functions\n",
    "\n",
    "# Re-run the plot code after fixing the missing numpy import\n",
    "x, y = 1, 2  # For F2 and F3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "# Plotting arrows for F2 (x=1) and F3 (y=2)\n",
    "for i in range(0, pca.components_.shape[1]):\n",
    "    ax.arrow(\n",
    "        0,\n",
    "        0,  # Start the arrow at the origin\n",
    "        pca.components_[x, i],  # F2 (PC2)\n",
    "        pca.components_[y, i],  # F3 (PC3)\n",
    "        head_width=0.07,\n",
    "        head_length=0.07,\n",
    "        width=0.02,\n",
    "    )\n",
    "\n",
    "    # Adding feature names next to the arrows\n",
    "    plt.text(pca.components_[x, i] + 0.05, pca.components_[y, i] + 0.05, features[i])\n",
    "\n",
    "# Displaying horizontal and vertical dashed lines at the origin\n",
    "plt.plot([-1, 1], [0, 0], color=\"grey\", ls=\"--\")\n",
    "plt.plot([0, 0], [-1, 1], color=\"grey\", ls=\"--\")\n",
    "\n",
    "# Labeling the axes with the percentage of variance explained\n",
    "plt.xlabel(\"F{} ({}%)\".format(x + 1, round(100 * pca.explained_variance_ratio_[x], 1)))\n",
    "plt.ylabel(\"F{} ({}%)\".format(y + 1, round(100 * pca.explained_variance_ratio_[y], 1)))\n",
    "\n",
    "plt.title(\"Cercle des corrélations (F{} et F{})\".format(x + 1, y + 1))\n",
    "\n",
    "# Add a unit circle for scale\n",
    "an = np.linspace(0, 2 * np.pi, 100)\n",
    "plt.plot(np.cos(an), np.sin(an))  # Circle with radius 1\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "intertia = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = range(1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df[\n",
    "    [\n",
    "        \"proteins_100g\",\n",
    "        \"carbohydrates_100g\",\n",
    "        \"sugars_100g\",\n",
    "        \"fat_100g\",\n",
    "        \"saturated-fat_100g\",\n",
    "    ]\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "for i in k_list:\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(X)\n",
    "    intertia.append(kmeans.inertia_)\n",
    "\n",
    "intertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "ax.set_ylabel(\"inertia\")\n",
    "ax.set_xlabel(\"n_cluster\")\n",
    "ax = plt.plot(k_list, intertia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "\n",
    "# Parcours des valeurs de k (nombre de clusters)\n",
    "range_n_clusters = range(2, 11)  # Testons pour k de 2 à 10\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Créer un modèle K-means avec k clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # Calculer le coefficient de silhouette pour cette valeur de k\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"Pour k={n_clusters}, le score de silhouette moyen est {silhouette_avg}\")\n",
    "\n",
    "# Affichage du graphique des scores de silhouette\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker=\"o\")\n",
    "plt.title(\"Score de silhouette pour différents k\")\n",
    "plt.xlabel(\"Nombre de clusters k\")\n",
    "plt.ylabel(\"Score de silhouette moyen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "kmeans.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {i: j for i, j in enumerate(list(\"ab\"))}\n",
    "dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [dd[i] for i in kmeans.labels_]\n",
    "labels[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"cluster\"] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X, hue=\"cluster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des variables\n",
    "X = cleaned_df[\n",
    "    [\n",
    "        \"proteins_100g\",\n",
    "        \"carbohydrates_100g\",\n",
    "        \"sugars_100g\",\n",
    "        \"fat_100g\",\n",
    "        \"saturated-fat_100g\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Application du K-means sur les données standardisées\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Ajout des labels de clusters au DataFrame\n",
    "X[\"Cluster\"] = clusters\n",
    "\n",
    "# Application de l'ACP pour la visualisation\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Création d'un DataFrame avec les composantes principales et les clusters\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=[\"F1\", \"F2\", \"F3\"])\n",
    "pca_df[\"Cluster\"] = clusters\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    pca_df[\"F1\"], pca_df[\"F2\"], c=pca_df[\"Cluster\"], cmap=\"viridis\", alpha=0.7\n",
    ")\n",
    "\n",
    "# Ajout des centroïdes projetés\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroids_pca = pca.transform(centroids)\n",
    "ax.scatter(\n",
    "    centroids_pca[:, 0],\n",
    "    centroids_pca[:, 1],\n",
    "    c=\"red\",\n",
    "    s=100,\n",
    "    marker=\"X\",\n",
    "    label=\"Centroïdes\",\n",
    ")\n",
    "\n",
    "# Étiquettes et titre\n",
    "ax.set_xlabel(\"Composante principale 1 (F1)\")\n",
    "ax.set_ylabel(\"Composante principale 2 (F2)\")\n",
    "ax.set_title(\"Clusters visualisés sur les composantes principales après K-means\")\n",
    "\n",
    "# Légende\n",
    "legend_labels = [\"Cluster 0\", \"Cluster 1\"]\n",
    "handles = [\n",
    "    plt.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        label=label,\n",
    "        markersize=10,\n",
    "        markerfacecolor=scatter.cmap(scatter.norm(i)),\n",
    "    )\n",
    "    for i, label in enumerate(legend_labels)\n",
    "]\n",
    "handles.append(\n",
    "    plt.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker=\"X\",\n",
    "        color=\"w\",\n",
    "        label=\"Centroïdes\",\n",
    "        markersize=10,\n",
    "        markerfacecolor=\"red\",\n",
    "    )\n",
    ")\n",
    "ax.legend(handles=handles, title=\"Légende\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"pnns_groups_2\"  # qualitative\n",
    "\n",
    "features = [\n",
    "    \"proteins_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "]\n",
    "for f in features:\n",
    "    # On ne garde que les dépenses\n",
    "    sous_echantillon = cleaned_df[\n",
    "        cleaned_df[f] > 0\n",
    "    ].copy()  # On remet les dépenses en positif\n",
    "    # On n'étudie pas les loyers car trop gros:\n",
    "\n",
    "    modalites = sous_echantillon[X].unique()\n",
    "    groupes = []\n",
    "    for m in modalites:\n",
    "        groupes.append(sous_echantillon[sous_echantillon[X] == m][f])\n",
    "\n",
    "    # Propriétés graphiques (pas très importantes)\n",
    "    medianprops = {\"color\": \"black\"}\n",
    "    meanprops = {\n",
    "        \"marker\": \"o\",\n",
    "        \"markeredgecolor\": \"black\",\n",
    "        \"markerfacecolor\": \"firebrick\",\n",
    "    }\n",
    "\n",
    "    plt.boxplot(\n",
    "        groupes,\n",
    "        labels=modalites,\n",
    "        showfliers=False,\n",
    "        medianprops=medianprops,\n",
    "        vert=False,\n",
    "        patch_artist=True,\n",
    "        showmeans=True,\n",
    "        meanprops=meanprops,\n",
    "    )\n",
    "    plt.title(f\"Boxplot of {f}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sous_echantillon = cleaned_df\n",
    "\n",
    "\n",
    "def eta_squared(x, y):\n",
    "    moyenne_y = y.mean()\n",
    "    classes = []\n",
    "    for classe in x.unique():\n",
    "        yi_classe = y[x == classe]\n",
    "        classes.append({\"ni\": len(yi_classe), \"moyenne_classe\": yi_classe.mean()})\n",
    "    SCT = sum([(yj - moyenne_y) ** 2 for yj in y])\n",
    "    SCE = sum([c[\"ni\"] * (c[\"moyenne_classe\"] - moyenne_y) ** 2 for c in classes])\n",
    "    return SCE / SCT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"proteins_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "]\n",
    "\n",
    "for f in features:\n",
    "    sous_echantillon = cleaned_df[\n",
    "        cleaned_df[f] > 0\n",
    "    ].copy()  # On remet les dépenses en positif\n",
    "    print(\n",
    "        f\"Eta squared for {f} is {eta_squared(sous_echantillon[X],sous_echantillon[f])}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Fonction principale pour lancer l'EDA\n",
    "def eda(data):\n",
    "    # 1. Aperçu des données\n",
    "    print(\"Aperçu des données :\")\n",
    "    print(data.head(), \"\\n\")\n",
    "    print(\"Informations sur les colonnes et types :\")\n",
    "    print(data.info(), \"\\n\")\n",
    "    print(\"Résumé statistique des données numériques :\")\n",
    "    print(data.describe(), \"\\n\")\n",
    "    print(\"Résumé des données catégorielles :\")\n",
    "    print(data.describe(include=\"object\"), \"\\n\")\n",
    "\n",
    "    # 2. Valeurs manquantes\n",
    "    print(\"Valeurs manquantes :\")\n",
    "    missing_data = data.isnull().sum()\n",
    "    print(missing_data[missing_data > 0], \"\\n\")\n",
    "\n",
    "    # Visualisation des valeurs manquantes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(data.isnull(), cbar=False, cmap=\"viridis\")\n",
    "    plt.title(\"Valeurs manquantes dans le jeu de données\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Distribution des variables numériques\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data[col], kde=True)\n",
    "        plt.title(f\"Distribution de {col}\")\n",
    "        plt.show()\n",
    "\n",
    "    # 4. Analyse des variables catégorielles\n",
    "    categorical_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "    for col in categorical_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(y=data[col], order=data[col].value_counts().index)\n",
    "        plt.title(f\"Répartition de {col}\")\n",
    "        plt.show()\n",
    "\n",
    "    # 5. Matrice de corrélation pour les variables numériques\n",
    "    if len(numeric_cols) > 1:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(data[numeric_cols].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "        plt.title(\"Matrice de corrélation des variables numériques\")\n",
    "        plt.show()\n",
    "\n",
    "    # 6. Outliers (valeurs aberrantes) avec Boxplot\n",
    "    for col in numeric_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x=data[col])\n",
    "        plt.title(f\"Boxplot de {col}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Utilisation : appelle cette fonction avec ton DataFrame\n",
    "# Exemple : eda(df)\n",
    "\n",
    "eda(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
